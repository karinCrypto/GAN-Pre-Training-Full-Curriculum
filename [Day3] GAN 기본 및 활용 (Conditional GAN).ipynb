{"cells":[{"cell_type":"markdown","id":"d3929011","metadata":{"id":"d3929011"},"source":["# ğŸ¯ Conditional GAN (CGAN) ì™„ì „ ì •ë³µ\n","\n","## ğŸ“š í•™ìŠµ ëª©í‘œ\n","\n","1. Conditional GANì˜ í•µì‹¬ ê°œë…ê³¼ Vanilla GANê³¼ì˜ ì°¨ì´ì  ì´í•´\n","2. ì¡°ê±´ ì •ë³´ë¥¼ ê²°í•©í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²• (Concatenation, Embedding, Projection) ë¹„êµ\n","3. TensorFlowì™€ PyTorchë¡œ CGAN êµ¬í˜„\n","4. Fashion MNISTë¡œ ì¡°ê±´ë¶€ ì´ë¯¸ì§€ ìƒì„± ì‹¤ìŠµ\n","5. CGANì˜ í‰ê°€ ì§€í‘œ (FID, Inception Score) ì´í•´\n","\n","---"]},{"cell_type":"markdown","id":"859bd41c","metadata":{"id":"859bd41c"},"source":["# ğŸ• 1êµì‹œ: DCGAN ë³µìŠµ ë° CGAN ì†Œê°œ\n","\n","---"]},{"cell_type":"markdown","id":"d13c88c4","metadata":{"id":"d13c88c4"},"source":["## 1.1 DCGAN í•µì‹¬ ë³µìŠµ\n","\n","### DCGANì˜ 5ê°€ì§€ ì„¤ê³„ ì›ì¹™\n","\n","| ì›ì¹™ | ë‚´ìš© | íš¨ê³¼ |\n","|------|------|------|\n","| 1ï¸âƒ£ | Pooling â†’ **Strided Conv** | í•™ìŠµ ê°€ëŠ¥í•œ ë‹¤ìš´ìƒ˜í”Œë§ |\n","| 2ï¸âƒ£ | **FC Layer ì œê±°** (ì¤‘ê°„ì¸µ) | ê³µê°„ êµ¬ì¡° ë³´ì¡´ |\n","| 3ï¸âƒ£ | **Batch Normalization** | í•™ìŠµ ì•ˆì •í™” |\n","| 4ï¸âƒ£ | **ì ì ˆí•œ í™œì„±í™” í•¨ìˆ˜** | Gradient íë¦„ ê°œì„  |\n","| 5ï¸âƒ£ | **Adam (Î²1=0.5)** | GANì— ìµœì í™” |\n","\n","### DCGANì˜ í•œê³„ì \n","\n","```\n","ë¬¸ì œ: ìƒì„± ì œì–´ ë¶ˆê°€ëŠ¥\n","\n","âŒ DCGANì˜ ê²½ìš°:\n","noise â†’ G â†’ ëœë¤í•œ ì´ë¯¸ì§€\n","â†’ ì–´ë–¤ ì´ë¯¸ì§€ê°€ ë‚˜ì˜¬ì§€ ëª¨ë¦„!\n","\n","ì˜ˆì‹œ:\n","- ìˆ«ì MNIST: ì–´ë–¤ ìˆ«ìê°€ ë‚˜ì˜¬ì§€ ëª¨ë¦„\n","- CelebA: ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ ì–¼êµ´ì´ ë‚˜ì˜¬ì§€ ëª¨ë¦„\n","- Fashion MNIST: ì–´ë–¤ ì¢…ë¥˜ì˜ ì˜·ì´ ë‚˜ì˜¬ì§€ ëª¨ë¦„\n","\n","ğŸ’¡ í•´ê²°ì±…: Conditional GAN (CGAN)\n","â†’ ì¡°ê±´ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì—¬ ì›í•˜ëŠ” ì´ë¯¸ì§€ ìƒì„±!\n","```\n","\n","---"]},{"cell_type":"markdown","id":"098c59bb","metadata":{"id":"098c59bb"},"source":["## 1.2 Conditional GAN (CGAN) ì†Œê°œ\n","\n","### CGANì˜ í•µì‹¬ ì•„ì´ë””ì–´\n","\n","**\"ì¡°ê±´ ì •ë³´(Condition)ë¥¼ ì¶”ê°€í•˜ì—¬ ìƒì„±ì„ ì œì–´í•˜ì!\"**\n","\n","```\n","GAN:    noise z â†’ G â†’ ëœë¤ ì´ë¯¸ì§€\n","\n","CGAN:   noise z + condition y â†’ G â†’ ì¡°ê±´ì— ë§ëŠ” ì´ë¯¸ì§€\n","        ì˜ˆ: z + \"ìˆ«ì 7\" â†’ \"7\" ì´ë¯¸ì§€ ìƒì„±\n","```\n","\n","### CGAN ë…¼ë¬¸ (2014)\n","\n","**\"Conditional Generative Adversarial Nets\"**\n","- ì €ì: Mehdi Mirza, Simon Osindero\n","- ë°œí‘œ: arXiv 2014\n","- í•µì‹¬: GANì— ì¡°ê±´ ì •ë³´ë¥¼ ì¶”ê°€í•œ ì²« ë²ˆì§¸ ë…¼ë¬¸\n","\n","---"]},{"cell_type":"markdown","id":"238dfb5d","metadata":{"id":"238dfb5d"},"source":["### GAN vs CGAN ë¹„êµ\n","\n","#### Vanilla GAN\n","\n","```\n","Generator:\n","  ì…ë ¥: z (ë…¸ì´ì¦ˆ)\n","  ì¶œë ¥: x (ì´ë¯¸ì§€)\n","  ìˆ˜ì‹: G(z) = x\n","\n","Discriminator:\n","  ì…ë ¥: x (ì´ë¯¸ì§€)\n","  ì¶œë ¥: ì§„ì§œ/ê°€ì§œ í™•ë¥ \n","  ìˆ˜ì‹: D(x) = [0, 1]\n","\n","í•™ìŠµ ëª©í‘œ:\n","  min_G max_D V(D,G) = E[log D(x)] + E[log(1 - D(G(z)))]\n","```\n","\n","#### Conditional GAN\n","\n","```\n","Generator:\n","  ì…ë ¥: z (ë…¸ì´ì¦ˆ) + y (ì¡°ê±´)\n","  ì¶œë ¥: x (ì¡°ê±´ì— ë§ëŠ” ì´ë¯¸ì§€)\n","  ìˆ˜ì‹: G(z, y) = x\n","\n","Discriminator:\n","  ì…ë ¥: x (ì´ë¯¸ì§€) + y (ì¡°ê±´)\n","  ì¶œë ¥: ì§„ì§œ/ê°€ì§œ í™•ë¥ \n","  ìˆ˜ì‹: D(x, y) = [0, 1]\n","\n","í•™ìŠµ ëª©í‘œ:\n","  min_G max_D V(D,G) = E[log D(x, y)] + E[log(1 - D(G(z, y), y))]\n","```\n","\n","**í•µì‹¬ ì°¨ì´:** ëª¨ë“  ê³³ì— ì¡°ê±´ yê°€ ì¶”ê°€ë¨!\n","\n","---"]},{"cell_type":"markdown","id":"8d1c4b9e","metadata":{"id":"8d1c4b9e"},"source":["### CGAN ì•„í‚¤í…ì²˜ ê°œìš”\n","\n","![](https://velog.velcdn.com/images%2Fwilko97%2Fpost%2F022d3c52-04ad-4e01-8307-f7c206a8ba1f%2Fimage.png)\n","\n","---"]},{"cell_type":"markdown","id":"05bf2251","metadata":{"id":"05bf2251"},"source":["## 1.3 ì¡°ê±´ ì •ë³´(Condition) ê²°í•© ë°©ë²•\n","\n","CGANì—ì„œ ì¡°ê±´ ì •ë³´ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\n","\n","---"]},{"cell_type":"markdown","id":"1d21359c","metadata":{"id":"1d21359c"},"source":["### ë°©ë²• 1: One-Hot Encoding + Concatenation (ì›ë³¸ ë…¼ë¬¸)\n","\n","**ê°€ì¥ ë‹¨ìˆœí•œ ë°©ë²•:**\n","\n","```python\n","# í´ë˜ìŠ¤ ë ˆì´ë¸”ì„ One-Hotìœ¼ë¡œ ë³€í™˜\n","y = 7  # ìˆ«ì 7\n","y_onehot = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  # 10ì°¨ì›\n","\n","# Generator\n","z = random_noise(100)  # 100ì°¨ì›\n","input_g = concat([z, y_onehot])  # 110ì°¨ì›\n","image = G(input_g)\n","\n","# Discriminator\n","# ë°©ë²• A: ì´ë¯¸ì§€ë¥¼ flattení•˜ì—¬ ê²°í•©\n","x_flat = flatten(image)  # 784ì°¨ì› (28Ã—28)\n","input_d = concat([x_flat, y_onehot])  # 794ì°¨ì›\n","output = D(input_d)\n","```\n","\n","**ì¥ì :**\n","- âœ… êµ¬í˜„ì´ ë§¤ìš° ê°„ë‹¨\n","- âœ… ì¶”ê°€ íŒŒë¼ë¯¸í„° ê±°ì˜ ì—†ìŒ\n","\n","**ë‹¨ì :**\n","- âŒ í´ë˜ìŠ¤ ìˆ˜ê°€ ë§ìœ¼ë©´ ë¹„íš¨ìœ¨ì  (1000ê°œ í´ë˜ìŠ¤ â†’ 1000ì°¨ì› ì¶”ê°€)\n","- âŒ í´ë˜ìŠ¤ ê°„ ìœ ì‚¬ë„ë¥¼ í‘œí˜„í•  ìˆ˜ ì—†ìŒ\n","- âŒ Discriminatorì—ì„œ ê³µê°„ ì •ë³´ ì†ì‹¤ (flatten í•„ìš”)\n","\n","---"]},{"cell_type":"markdown","id":"86e19a7b","metadata":{"id":"86e19a7b"},"source":["### ë°©ë²• 2: Embedding + Concatenation (ì¼ë°˜ì )\n","\n","![](https://blog.kakaocdn.net/dna/cKUQKZ/btrQrrA21lu/AAAAAAAAAAAAAAAAAAAAAMMjchx7ANe_VJ5k7VGNM6iw4vGW9sEpB_CO9ZKjpWQD/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1764514799&allow_ip=&allow_referer=&signature=zMtRPd8IznSEWO2%2BwXJh%2FXfW9Wk%3D)\n","\n","**Embeddingì„ ì‚¬ìš©í•œ ê°œì„  ë°©ë²•:**\n","\n","```python\n","# Embedding Layer ì‚¬ìš©\n","embedding_layer = Embedding(num_classes=10, embedding_dim=50)\n","\n","# Generator\n","z = random_noise(100)  # 100ì°¨ì›\n","y_embed = embedding_layer(y)  # 10 â†’ 50ì°¨ì›\n","input_g = concat([z, y_embed])  # 150ì°¨ì›\n","image = G(input_g)\n","\n","# Discriminator\n","y_embed = embedding_layer(y)  # 50ì°¨ì›\n","y_map = Linear(y_embed)  # 50 â†’ 784\n","y_map = reshape(y_map, [28, 28, 1])  # ê³µê°„ êµ¬ì¡°\n","input_d = concat([image, y_map], axis=channel)  # 28Ã—28Ã—2\n","output = D(input_d)\n","```\n","\n","**Embeddingì˜ ì—­í• :**\n","```\n","í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ í•™ìŠµ ê°€ëŠ¥í•œ ê³ ì°¨ì› ë²¡í„°\n","\n","ì˜ˆì‹œ (embedding_dim=3):\n","0 (T-shirt) â†’ [0.2, -0.5,  0.8]\n","1 (Trouser) â†’ [0.3,  0.1, -0.4]\n","7 (Sneaker) â†’ [-0.6, 0.7,  0.2]\n","\n","ìœ ì‚¬í•œ í´ë˜ìŠ¤ëŠ” ìœ ì‚¬í•œ ë²¡í„°ë¥¼ í•™ìŠµ!\n","```\n","\n","**ì¥ì :**\n","- âœ… í´ë˜ìŠ¤ ê°„ ìœ ì‚¬ë„ í•™ìŠµ ê°€ëŠ¥\n","- âœ… íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  (í´ë˜ìŠ¤ ìˆ˜ Ã— ì„ë² ë”© ì°¨ì›)\n","- âœ… Discriminatorì—ì„œ ê³µê°„ ì •ë³´ ë³´ì¡´\n","\n","**ë‹¨ì :**\n","- âŒ ì¶”ê°€ íŒŒë¼ë¯¸í„° í•„ìš” (Embedding layer)\n","- âŒ One-Hotë³´ë‹¤ ë³µì¡\n","\n","---"]},{"cell_type":"markdown","id":"f426766b","metadata":{"id":"f426766b"},"source":["### ë°©ë²• 3: Projection Discriminator (ìµœì‹  ê¸°ë²•)\n","\n","**BigGAN, StyleGAN ë“±ì—ì„œ ì‚¬ìš©:**\n","\n","```python\n","# Discriminatorì—ì„œ Projection ì‚¬ìš©\n","# GeneratorëŠ” ë™ì¼ (Embedding + Concat)\n","\n","# Discriminator\n","features = Conv_layers(image)  # (batch, feature_dim)\n","y_embed = Embedding(y)  # (batch, embedding_dim)\n","\n","# Projection: ë‚´ì (dot product) ì‚¬ìš©\n","output = Linear(features) + dot(features, y_embed)\n","#        â””â”€ ë¬´ì¡°ê±´ íŒë³„      â””â”€ ì¡°ê±´ë¶€ íŒë³„\n","```\n","\n","> ì´ë¯¸ì§€ íŠ¹ì§•ê³¼ ë¼ë²¨ ì„ë² ë”©ì˜ ìœ ì‚¬ë„ë¥¼ ì§ì ‘ ê³„ì‚°í•´ì„œ,\n",">\n","> ë¼ë²¨ì— ë§ëŠ” ì´ë¯¸ì§€ì¸ì§€ ë‚´ì (dot product)ìœ¼ë¡œ íŒë³„í•˜ëŠ” ê°•ë ¥í•œ ì¡°ê±´ ê²°í•© ë°©ì‹.\n","\n","**ìˆ˜ì‹:**\n","$$\n","D(x, y) = \\sigma(\\phi(x)^T W + \\phi(x)^T E(y))\n","$$\n","\n","- $\\phi(x)$: CNN íŠ¹ì§• ë²¡í„°\n","- $W$: í•™ìŠµ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜\n","- $E(y)$: ì„ë² ë”© ë²¡í„°\n","\n","**ì¥ì :**\n","- âœ… ìµœê³  ì„±ëŠ¥ (BigGAN, StyleGAN2 ë“±)\n","- âœ… ì¡°ê±´ê³¼ ì´ë¯¸ì§€ì˜ ìƒí˜¸ì‘ìš© ëª…í™•íˆ ëª¨ë¸ë§\n","- âœ… íŒŒë¼ë¯¸í„° íš¨ìœ¨ì \n","\n","**ë‹¨ì :**\n","- âŒ êµ¬í˜„ì´ ë³µì¡\n","- âŒ ì‘ì€ ë°ì´í„°ì…‹ì—ì„œëŠ” ì˜¤ë²„í—¤ë“œ\n","\n","---"]},{"cell_type":"markdown","id":"694c1db6","metadata":{"id":"694c1db6"},"source":["### ì„¸ ê°€ì§€ ë°©ë²• ë¹„êµ ìš”ì•½\n","\n","| ë°©ë²• | íŒŒë¼ë¯¸í„° | ì„±ëŠ¥ | êµ¬í˜„ ë‚œì´ë„ | ì‚¬ìš©ì²˜ |\n","|------|---------|------|------------|--------|\n","| **One-Hot** | ìµœì†Œ | ë³´í†µ | ë§¤ìš° ì‰¬ì›€ | í”„ë¡œí† íƒ€ì…, í´ë˜ìŠ¤ ìˆ˜ ì ìŒ |\n","| **Embedding** | ì¤‘ê°„ | ì¢‹ìŒ | ì‰¬ì›€ | ì¼ë°˜ì ì¸ CGAN |\n","| **Projection** | ì¤‘ê°„ | ìµœê³  | ì–´ë ¤ì›€ | ëŒ€ê·œëª¨ GAN (BigGAN ë“±) |\n","\n","**ë³¸ ê°•ì˜ì—ì„œëŠ” Embedding + Concatenation ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.**\n","(ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ê³ , ì„±ëŠ¥ê³¼ êµ¬í˜„ì˜ ê· í˜•ì´ ì¢‹ìŒ)\n","\n","---"]},{"cell_type":"markdown","id":"3bb7ee69","metadata":{"id":"3bb7ee69"},"source":["## 1.4 CGANì˜ í™œìš© ì‚¬ë¡€\n","\n","### 1. ì¡°ê±´ë¶€ ì´ë¯¸ì§€ ìƒì„±\n","\n","```\n","ì˜ˆì‹œ 1: MNIST\n","- ì¡°ê±´: ìˆ«ì í´ë˜ìŠ¤ (0~9)\n","- ìƒì„±: \"7\"ì„ ì—¬ëŸ¬ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±\n","\n","ì˜ˆì‹œ 2: Fashion MNIST\n","- ì¡°ê±´: ì˜· ì¢…ë¥˜ (T-shirt, Sneaker, ...)\n","- ìƒì„±: ì›í•˜ëŠ” ì¢…ë¥˜ì˜ ì˜·ë§Œ ìƒì„±\n","\n","ì˜ˆì‹œ 3: CelebA\n","- ì¡°ê±´: ì†ì„± (ì•ˆê²½, ê¸ˆë°œ, ì›ƒìŒ, ...)\n","- ìƒì„±: \"ì•ˆê²½ ì“´ ê¸ˆë°œ ì—¬ì„±\" ìƒì„±\n","```\n","\n","### 2. Image-to-Image Translation\n","\n","```\n","Pix2Pix:\n","- ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì¡°ê±´ìœ¼ë¡œ ì‚¬ìš©\n","- ì˜ˆ: ìŠ¤ì¼€ì¹˜ â†’ ì‚¬ì§„, ë‚® â†’ ë°¤, í‘ë°± â†’ ì»¬ëŸ¬\n","\n","êµ¬ì¡°:\n","G(z, sketch) â†’ photo\n","D(photo, sketch) â†’ ì§„ì§œ/ê°€ì§œ\n","```\n","\n","### 3. Super Resolution\n","\n","```\n","ì €í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ì¡°ê±´ìœ¼ë¡œ ì‚¬ìš©:\n","G(z, low_res) â†’ high_res\n","```\n","\n","### 4. Text-to-Image\n","\n","```\n","í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ì¡°ê±´ìœ¼ë¡œ ì‚¬ìš©:\n","G(z, \"a bird with red wings\") â†’ ì´ë¯¸ì§€\n","```\n","\n","---"]},{"cell_type":"markdown","id":"b68f5f4a","metadata":{"id":"b68f5f4a"},"source":["## 1.5 CGAN Loss í•¨ìˆ˜ ìƒì„¸ ë¶„ì„\n","\n","### Conditional GANì˜ Min-Max ê²Œì„\n","\n","$$\n","\\min_G \\max_D V(D, G) = \\mathbb{E}_{x,y \\sim p_{data}}[\\log D(x, y)] + \\mathbb{E}_{z \\sim p_z, y \\sim p_y}[\\log(1 - D(G(z, y), y))]\n","$$\n","\n","**Vanilla GANê³¼ì˜ ì°¨ì´:**\n","- ëª¨ë“  í•­ì— ì¡°ê±´ $y$ê°€ ì¶”ê°€ë¨\n","- $y$ëŠ” ì‹¤ì œ ë°ì´í„°ì˜ ë ˆì´ë¸” ë¶„í¬ì—ì„œ ìƒ˜í”Œë§\n","\n","---"]},{"cell_type":"markdown","id":"a2a7b5c0","metadata":{"id":"a2a7b5c0"},"source":["### Loss ê³„ì‚° ë‹¨ê³„ë³„ ë¶„ì„\n","\n","#### Generator í•™ìŠµ\n","\n","```python\n","# 1. ëœë¤ ë…¸ì´ì¦ˆì™€ ëœë¤ ë ˆì´ë¸” ìƒ˜í”Œë§\n","z = sample_noise(batch_size, noise_dim)\n","y = sample_labels(batch_size, num_classes)\n","\n","# 2. ê°€ì§œ ì´ë¯¸ì§€ ìƒì„±\n","x_fake = G(z, y)\n","\n","# 3. Discriminatorë¡œ íŒë³„\n","d_fake = D(x_fake, y)  # ì¡°ê±´ yë„ í•¨ê»˜ ì…ë ¥!\n","\n","# 4. Generator Loss\n","# ëª©í‘œ: D(G(z, y), y)ë¥¼ 1ì— ê°€ê¹ê²Œ\n","g_loss = BCE(d_fake, ones)\n","```\n","\n","**í•µì‹¬:** GeneratorëŠ” \"ì¡°ê±´ yì— ë§ëŠ”\" ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±\n","\n","#### Discriminator í•™ìŠµ\n","\n","```python\n","# 1. ì§„ì§œ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”\n","x_real, y_real = sample_real_data()\n","d_real = D(x_real, y_real)\n","d_loss_real = BCE(d_real, ones)\n","\n","# 2. ê°€ì§œ ì´ë¯¸ì§€ ìƒì„±\n","z = sample_noise()\n","y_fake = sample_labels()  # ëœë¤ ë ˆì´ë¸”\n","x_fake = G(z, y_fake)\n","d_fake = D(x_fake, y_fake)\n","d_loss_fake = BCE(d_fake, zeros)\n","\n","# 3. ì´ Loss\n","d_loss = d_loss_real + d_loss_fake\n","```\n","\n","**í•µì‹¬:** DiscriminatorëŠ” ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì˜ \"í˜ì–´ë§\"ì´ ë§ëŠ”ì§€ íŒë³„\n","\n","---"]},{"cell_type":"markdown","id":"74ce081d","metadata":{"id":"74ce081d"},"source":["### CGAN Lossì˜ ì§ê´€ì  ì´í•´\n","\n","```\n","ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜¬ë°”ë¥¸ í˜ì–´ë§\n","â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","â”‚ ì´ë¯¸ì§€: ìŠ¤ë‹ˆì»¤ì¦ˆ ì‚¬ì§„                 â”‚\n","â”‚ ë ˆì´ë¸”: \"Sneaker\" (7)                â”‚\n","â”‚ â†’ Dì˜ íŒë‹¨: \"ì§„ì§œ\" (1)               â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","\n","ì‹œë‚˜ë¦¬ì˜¤ 2: ì˜ëª»ëœ í˜ì–´ë§\n","â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","â”‚ ì´ë¯¸ì§€: ìŠ¤ë‹ˆì»¤ì¦ˆ ì‚¬ì§„                 â”‚\n","â”‚ ë ˆì´ë¸”: \"T-shirt\" (0)                â”‚\n","â”‚ â†’ Dì˜ íŒë‹¨: \"ê°€ì§œ\" (0)               â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","\n","ì‹œë‚˜ë¦¬ì˜¤ 3: ê°€ì§œ ì´ë¯¸ì§€\n","â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","â”‚ ì´ë¯¸ì§€: Gê°€ ìƒì„±í•œ ìŠ¤ë‹ˆì»¤ì¦ˆ           â”‚\n","â”‚ ë ˆì´ë¸”: \"Sneaker\" (7)                â”‚\n","â”‚ â†’ Dì˜ íŒë‹¨: \"ê°€ì§œ\" (0)               â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","```\n","\n","**Discriminatorì˜ ì—­í• :**\n","1. ì§„ì§œ ì´ë¯¸ì§€ + ì˜¬ë°”ë¥¸ ë ˆì´ë¸” â†’ 1\n","2. ì§„ì§œ ì´ë¯¸ì§€ + ì˜ëª»ëœ ë ˆì´ë¸” â†’ 0\n","3. ê°€ì§œ ì´ë¯¸ì§€ + ì„ì˜ ë ˆì´ë¸” â†’ 0\n","\n","**Generatorì˜ ì—­í• :**\n","- ì¡°ê±´ yì— \"ì •í™•íˆ ë§ëŠ”\" ì´ë¯¸ì§€ ìƒì„±\n","- Dê°€ (G(z,y), y)ë¥¼ 1ë¡œ íŒë³„í•˜ë„ë¡\n","\n","---"]},{"cell_type":"markdown","id":"130479ad","metadata":{"id":"130479ad"},"source":["# ğŸ• 2êµì‹œ: CGAN êµ¬í˜„ (TensorFlow)\n","\n","---"]},{"cell_type":"markdown","id":"9339c638","metadata":{"id":"9339c638"},"source":["## 2.1 í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„"]},{"cell_type":"code","execution_count":null,"id":"59911a28","metadata":{"id":"59911a28"},"outputs":[],"source":["\n","# Colabìš© í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ë° ì„¤ì • (í•œ ë²ˆë§Œ ì‹¤í–‰)\n","import os\n","import subprocess\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","import tensorflow as tf\n","import numpy as np\n","\n","# NanumGothic ì„¤ì¹˜ ë° í°íŠ¸ ìºì‹œ ê°±ì‹ \n","if not os.path.exists('/usr/share/fonts/truetype/nanum/NanumGothic.ttf'):\n","    subprocess.check_call(['apt-get', '-qq', '-y', 'install', 'fonts-nanum'])\n","    subprocess.check_call(['fc-cache', '-fv'])\n","\n","# matplotlibì— í°íŠ¸ ë“±ë¡\n","font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n","if os.path.exists(font_path):\n","    fm.fontManager.addfont(font_path)\n","    mpl.rcParams['font.family'] = 'NanumGothic'\n","    mpl.rcParams['axes.unicode_minus'] = False\n","else:\n","    print(\"NanumGothic í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ê°€ ì •ìƒì ìœ¼ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n","\n","print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n","print(\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ\")\n","\n","# GPU í™•ì¸\n","print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n","print(f\"GPU ì‚¬ìš© ê°€ëŠ¥: {tf.config.list_physical_devices('GPU')}\")\n","\n","# ëœë¤ ì‹œë“œ ì„¤ì •\n","tf.random.set_seed(42)\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":null,"id":"860abe3b","metadata":{"id":"860abe3b"},"outputs":[],"source":["# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n","IMG_SIZE = 28  # Fashion MNIST: 28Ã—28\n","CHANNELS = 1  # Grayscale\n","NUM_CLASSES = 10  # 10ê°œ í´ë˜ìŠ¤\n","BATCH_SIZE = 128\n","NOISE_DIM = 100\n","EMBEDDING_DIM = 50  # í´ë˜ìŠ¤ ì„ë² ë”© ì°¨ì›\n","EPOCHS = 50\n","LR = 0.0002\n","BETA1 = 0.5\n","\n","# í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜\n","CLASS_NAMES = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","print(\"âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ\")\n","print(f\"   - ì´ë¯¸ì§€ í¬ê¸°: {IMG_SIZE}Ã—{IMG_SIZE}Ã—{CHANNELS}\")\n","print(f\"   - í´ë˜ìŠ¤ ìˆ˜: {NUM_CLASSES}\")\n","print(f\"   - ì„ë² ë”© ì°¨ì›: {EMBEDDING_DIM}\")"]},{"cell_type":"code","execution_count":null,"id":"e09aa933","metadata":{"id":"e09aa933"},"outputs":[],"source":["# Fashion MNIST ë°ì´í„°ì…‹ ë¡œë“œ\n","(x_train, y_train), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","# ì „ì²˜ë¦¬: [0, 255] â†’ [-1, 1]\n","x_train = x_train.astype(\"float32\")\n","x_train = (x_train - 127.5) / 127.5\n","x_train = np.expand_dims(x_train, axis=-1)  # (60000, 28, 28, 1)\n","\n","print(f\"\\nâœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ\")\n","print(f\"   - ì´ë¯¸ì§€ shape: {x_train.shape}\")\n","print(f\"   - ë ˆì´ë¸” shape: {y_train.shape}\")\n","print(f\"   - ê°’ ë²”ìœ„: [{x_train.min():.2f}, {x_train.max():.2f}]\")\n","\n","# Dataset ìƒì„±\n","train_dataset = (\n","    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","    .shuffle(60000)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n",")"]},{"cell_type":"code","execution_count":null,"id":"23b251e9","metadata":{"id":"23b251e9"},"outputs":[],"source":["# ë°ì´í„° ìƒ˜í”Œ ì‹œê°í™”\n","sample_images, sample_labels = next(iter(train_dataset))\n","print(f\"ë°°ì¹˜ shape: {sample_images.shape}\")\n","\n","fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n","for i in range(10):\n","    ax = axes[i // 5, i % 5]\n","    # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ì²« ë²ˆì§¸ ìƒ˜í”Œ ì°¾ê¸°\n","    idx = tf.where(sample_labels == i)[0][0]\n","    img = (sample_images[idx].numpy() + 1) / 2\n","    ax.imshow(img.squeeze(), cmap=\"gray\")\n","    ax.set_title(f\"{i}: {CLASS_NAMES[i]}\", fontsize=10)\n","    ax.axis(\"off\")\n","\n","plt.suptitle(\"Fashion MNIST í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ\", fontsize=14)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"b580b872","metadata":{"lines_to_next_cell":2,"id":"b580b872"},"source":["## 2.2 Conditional Generator êµ¬í˜„ (TensorFlow)"]},{"cell_type":"code","execution_count":null,"id":"ee3a4a6d","metadata":{"id":"ee3a4a6d"},"outputs":[],"source":["def build_conditional_generator(noise_dim=100, num_classes=10, embedding_dim=50):\n","    \"\"\"\n","    Conditional Generator êµ¬í˜„ (TensorFlow)\n","\n","    êµ¬ì¡°:\n","        1. ë…¸ì´ì¦ˆ ì…ë ¥ (noise_dim)\n","        2. ë ˆì´ë¸” ì…ë ¥ (ì •ìˆ˜) â†’ Embedding (embedding_dim)\n","        3. Concatenate [noise, embedding]\n","        4. Dense + Reshape\n","        5. ConvTranspose layers\n","\n","    Args:\n","        noise_dim: ë…¸ì´ì¦ˆ ë²¡í„° ì°¨ì›\n","        num_classes: í´ë˜ìŠ¤ ê°œìˆ˜\n","        embedding_dim: ë ˆì´ë¸” ì„ë² ë”© ì°¨ì›\n","\n","    Returns:\n","        tf.keras.Model\n","    \"\"\"\n","\n","    # ========================================\n","    # ì…ë ¥ì¸µ ì •ì˜\n","    # ========================================\n","    # ì…ë ¥ 1: ë…¸ì´ì¦ˆ ë²¡í„°\n","    noise_input = layers.Input(shape=(noise_dim,), name=\"noise_input\")\n","    # ì˜ˆ: (batch_size, 100)\n","\n","    # ì…ë ¥ 2: ë ˆì´ë¸” (ì •ìˆ˜)\n","    label_input = layers.Input(shape=(1,), dtype=tf.int32, name=\"label_input\")\n","    # ì˜ˆ: (batch_size, 1) - ê° ê°’ì€ 0~9 ì‚¬ì´ì˜ ì •ìˆ˜\n","\n","    # ========================================\n","    # ë ˆì´ë¸” ì„ë² ë”©\n","    # ========================================\n","    # Embedding Layer: ì •ìˆ˜ â†’ ê³ ì°¨ì› ë²¡í„°\n","    # input_dim: í´ë˜ìŠ¤ ê°œìˆ˜ (10)\n","    # output_dim: ì„ë² ë”© ì°¨ì› (50)\n","    label_embedding = layers.Embedding(\n","        input_dim=num_classes, output_dim=embedding_dim, name=\"label_embedding\"\n","    )(label_input)\n","    # ì…ë ¥: (batch_size, 1) - ì •ìˆ˜\n","    # ì¶œë ¥: (batch_size, 1, embedding_dim)\n","    # ì˜ˆ: (128, 1, 50)\n","\n","    # Flatten: (batch_size, 1, embedding_dim) â†’ (batch_size, embedding_dim)\n","    label_embedding = layers.Flatten()(label_embedding)\n","    # ì˜ˆ: (128, 1, 50) â†’ (128, 50)\n","\n","    # ========================================\n","    # ë…¸ì´ì¦ˆì™€ ì„ë² ë”© ê²°í•©\n","    # ========================================\n","    # Concatenate: [noise, label_embedding]\n","    # noise: (batch_size, 100)\n","    # label_embedding: (batch_size, 50)\n","    # â†’ gen_input: (batch_size, 150)\n","    gen_input = layers.Concatenate()([noise_input, label_embedding])\n","\n","    # ========================================\n","    # Generator ë©”ì¸ ë„¤íŠ¸ì›Œí¬\n","    # ========================================\n","    # Dense: 150 â†’ 7Ã—7Ã—256 = 12,544\n","    x = layers.Dense(7 * 7 * 256, use_bias=False)(gen_input)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","\n","    # Reshape: (batch_size, 12544) â†’ (batch_size, 7, 7, 256)\n","    x = layers.Reshape((7, 7, 256))(x)\n","\n","    # ConvTranspose 1: 7Ã—7 â†’ 14Ã—14\n","    x = layers.Conv2DTranspose(128, 4, 2, \"same\", use_bias=False)(x)\n","    # ì¶œë ¥: (batch_size, 14, 14, 128)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","\n","    # ConvTranspose 2 (ì¶œë ¥ì¸µ): 14Ã—14 â†’ 28Ã—28\n","    x = layers.Conv2DTranspose(1, 4, 2, \"same\", use_bias=False, activation=\"tanh\")(x)\n","    # ì¶œë ¥: (batch_size, 28, 28, 1)\n","\n","    # ========================================\n","    # ëª¨ë¸ ì •ì˜\n","    # ========================================\n","    model = tf.keras.Model(\n","        inputs=[noise_input, label_input], outputs=x, name=\"Conditional_Generator\"\n","    )\n","\n","    return model\n","\n","\n","# Generator ìƒì„±\n","generator = build_conditional_generator(NOISE_DIM, NUM_CLASSES, EMBEDDING_DIM)\n","generator.summary()"]},{"cell_type":"code","execution_count":null,"id":"db89c658","metadata":{"id":"db89c658"},"outputs":[],"source":["# Generator í…ŒìŠ¤íŠ¸\n","print(\"\\nğŸ§ª Conditional Generator í…ŒìŠ¤íŠ¸\")\n","print(\"=\" * 60)\n","\n","# í…ŒìŠ¤íŠ¸ ì…ë ¥\n","test_noise = tf.random.normal([4, NOISE_DIM])\n","test_labels = tf.constant([[0], [3], [7], [9]])  # T-shirt, Dress, Sneaker, Ankle boot\n","\n","print(f\"ì…ë ¥ ë…¸ì´ì¦ˆ shape: {test_noise.shape}\")\n","print(f\"ì…ë ¥ ë ˆì´ë¸”: {test_labels.numpy().flatten()}\")\n","print(f\"ë ˆì´ë¸” ì´ë¦„: {[CLASS_NAMES[i] for i in test_labels.numpy().flatten()]}\")\n","\n","# Generator í†µê³¼\n","test_output = generator([test_noise, test_labels], training=False)\n","print(f\"\\nì¶œë ¥ ì´ë¯¸ì§€ shape: {test_output.shape}\")\n","print(\n","    f\"ì¶œë ¥ ê°’ ë²”ìœ„: [{test_output.numpy().min():.3f}, {test_output.numpy().max():.3f}]\"\n",")\n","\n","# ì‹œê°í™”\n","fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n","for i, ax in enumerate(axes):\n","    img = (test_output[i].numpy() + 1) / 2\n","    ax.imshow(img.squeeze(), cmap=\"gray\")\n","    ax.set_title(f\"{CLASS_NAMES[test_labels[i, 0]]}\", fontsize=10)\n","    ax.axis(\"off\")\n","plt.suptitle(\"Generator ì´ˆê¸° ì¶œë ¥ (í•™ìŠµ ì „)\", fontsize=14)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"697cc71c","metadata":{"lines_to_next_cell":2,"id":"697cc71c"},"source":["## 2.3 Conditional Discriminator êµ¬í˜„ (TensorFlow)"]},{"cell_type":"code","execution_count":null,"id":"b1de51d6","metadata":{"id":"b1de51d6"},"outputs":[],"source":["def build_conditional_discriminator(num_classes=10, embedding_dim=50):\n","    \"\"\"\n","    Conditional Discriminator êµ¬í˜„ (TensorFlow)\n","\n","    êµ¬ì¡°:\n","        1. ì´ë¯¸ì§€ ì…ë ¥ (28Ã—28Ã—1)\n","        2. ë ˆì´ë¸” ì…ë ¥ (ì •ìˆ˜) â†’ Embedding â†’ Linear â†’ Reshape â†’ 28Ã—28Ã—1 ë§µ\n","        3. Concatenate [image, label_map] â†’ 28Ã—28Ã—2\n","        4. Conv layers\n","        5. Dense â†’ ì¶œë ¥ (ì§„ì§œ/ê°€ì§œ)\n","\n","    Args:\n","        num_classes: í´ë˜ìŠ¤ ê°œìˆ˜\n","        embedding_dim: ë ˆì´ë¸” ì„ë² ë”© ì°¨ì›\n","\n","    Returns:\n","        tf.keras.Model\n","    \"\"\"\n","\n","    # ========================================\n","    # ì…ë ¥ì¸µ ì •ì˜\n","    # ========================================\n","    # ì…ë ¥ 1: ì´ë¯¸ì§€\n","    image_input = layers.Input(shape=(28, 28, 1), name=\"image_input\")\n","    # ì˜ˆ: (batch_size, 28, 28, 1)\n","\n","    # ì…ë ¥ 2: ë ˆì´ë¸” (ì •ìˆ˜)\n","    label_input = layers.Input(shape=(1,), dtype=tf.int32, name=\"label_input\")\n","    # ì˜ˆ: (batch_size, 1)\n","\n","    # ========================================\n","    # ë ˆì´ë¸” ì„ë² ë”© ë° ë§µ ìƒì„±\n","    # ========================================\n","    # Step 1: Embedding\n","    label_embedding = layers.Embedding(input_dim=num_classes, output_dim=embedding_dim)(\n","        label_input\n","    )\n","    # ì¶œë ¥: (batch_size, 1, embedding_dim)\n","\n","    label_embedding = layers.Flatten()(label_embedding)\n","    # ì¶œë ¥: (batch_size, embedding_dim)\n","    # ì˜ˆ: (128, 50)\n","\n","    # Step 2: Linearë¡œ 28Ã—28 í¬ê¸°ë¡œ ë³€í™˜\n","    label_map = layers.Dense(28 * 28)(label_embedding)\n","    # ì¶œë ¥: (batch_size, 784)\n","\n","    # Step 3: Reshape to 28Ã—28Ã—1\n","    label_map = layers.Reshape((28, 28, 1))(label_map)\n","    # ì¶œë ¥: (batch_size, 28, 28, 1)\n","\n","    # ========================================\n","    # ì´ë¯¸ì§€ì™€ ë ˆì´ë¸” ë§µ ê²°í•©\n","    # ========================================\n","    # Concatenate: [image, label_map]\n","    # image: (batch_size, 28, 28, 1)\n","    # label_map: (batch_size, 28, 28, 1)\n","    # â†’ disc_input: (batch_size, 28, 28, 2)\n","    disc_input = layers.Concatenate(axis=-1)([image_input, label_map])\n","\n","    # ========================================\n","    # Discriminator ë©”ì¸ ë„¤íŠ¸ì›Œí¬\n","    # ========================================\n","    # Conv 1: 28Ã—28 â†’ 14Ã—14\n","    x = layers.Conv2D(64, 4, 2, \"same\")(disc_input)\n","    # ì¶œë ¥: (batch_size, 14, 14, 64)\n","    x = layers.LeakyReLU(0.2)(x)\n","\n","    # Conv 2: 14Ã—14 â†’ 7Ã—7\n","    x = layers.Conv2D(128, 4, 2, \"same\", use_bias=False)(x)\n","    # ì¶œë ¥: (batch_size, 7, 7, 128)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(0.2)(x)\n","\n","    # Flatten + Dense\n","    x = layers.Flatten()(x)\n","    # ì¶œë ¥: (batch_size, 6272)\n","\n","    x = layers.Dense(1)(x)\n","    # ì¶œë ¥: (batch_size, 1) - Logit ê°’ (Sigmoid ì—†ìŒ)\n","\n","    # ========================================\n","    # ëª¨ë¸ ì •ì˜\n","    # ========================================\n","    model = tf.keras.Model(\n","        inputs=[image_input, label_input], outputs=x, name=\"Conditional_Discriminator\"\n","    )\n","\n","    return model\n","\n","\n","# Discriminator ìƒì„±\n","discriminator = build_conditional_discriminator(NUM_CLASSES, EMBEDDING_DIM)\n","discriminator.summary()"]},{"cell_type":"code","execution_count":null,"id":"1136e148","metadata":{"id":"1136e148"},"outputs":[],"source":["# Discriminator í…ŒìŠ¤íŠ¸\n","print(\"\\nğŸ§ª Conditional Discriminator í…ŒìŠ¤íŠ¸\")\n","print(\"=\" * 60)\n","\n","# ì§„ì§œ ì´ë¯¸ì§€\n","real_sample = sample_images[:4]\n","real_labels = tf.reshape(sample_labels[:4], [-1, 1])\n","print(f\"ì§„ì§œ ì´ë¯¸ì§€ shape: {real_sample.shape}\")\n","print(f\"ì§„ì§œ ë ˆì´ë¸”: {real_labels.numpy().flatten()}\")\n","\n","# ê°€ì§œ ì´ë¯¸ì§€\n","fake_sample = generator([test_noise, test_labels], training=False)\n","print(f\"ê°€ì§œ ì´ë¯¸ì§€ shape: {fake_sample.shape}\")\n","print(f\"ê°€ì§œ ë ˆì´ë¸”: {test_labels.numpy().flatten()}\")\n","\n","# Discriminator í†µê³¼\n","real_output = discriminator([real_sample, real_labels], training=False)\n","fake_output = discriminator([fake_sample, test_labels], training=False)\n","\n","print(f\"\\nì§„ì§œ ì´ë¯¸ì§€ íŒë³„ ê²°ê³¼: {real_output.numpy().flatten()}\")\n","print(f\"ê°€ì§œ ì´ë¯¸ì§€ íŒë³„ ê²°ê³¼: {fake_output.numpy().flatten()}\")\n","print(\"=\" * 60)"]},{"cell_type":"markdown","id":"6402da97","metadata":{"id":"6402da97"},"source":["## 2.4 ì†ì‹¤ í•¨ìˆ˜ ë° Optimizer ì„¤ì •"]},{"cell_type":"code","execution_count":null,"id":"4764ba25","metadata":{"id":"4764ba25"},"outputs":[],"source":["# BCEWithLogitsLoss\n","cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","# Optimizer\n","optimizer_g = tf.keras.optimizers.Adam(learning_rate=LR, beta_1=BETA1, beta_2=0.999)\n","optimizer_d = tf.keras.optimizers.Adam(learning_rate=LR, beta_1=BETA1, beta_2=0.999)\n","\n","print(\"âœ… ì†ì‹¤ í•¨ìˆ˜ ë° Optimizer ì„¤ì • ì™„ë£Œ\")"]},{"cell_type":"markdown","id":"9c14f715","metadata":{"lines_to_next_cell":2,"id":"9c14f715"},"source":["## 2.5 í•™ìŠµ Step í•¨ìˆ˜ êµ¬í˜„"]},{"cell_type":"code","execution_count":null,"id":"2cf9e74d","metadata":{"id":"2cf9e74d"},"outputs":[],"source":["@tf.function\n","def train_step(real_images, real_labels):\n","    \"\"\"\n","    CGAN í•œ ìŠ¤í… í•™ìŠµ (TensorFlow)\n","\n","    Args:\n","        real_images: ì§„ì§œ ì´ë¯¸ì§€ (batch_size, 28, 28, 1)\n","        real_labels: ì§„ì§œ ë ˆì´ë¸” (batch_size,)\n","\n","    Returns:\n","        d_loss, g_loss\n","    \"\"\"\n","    batch_size = tf.shape(real_images)[0]\n","\n","    # ë ˆì´ë¸” reshape: (batch_size,) â†’ (batch_size, 1)\n","    real_labels = tf.reshape(real_labels, [-1, 1])\n","\n","    # ========================================\n","    # Discriminator í•™ìŠµ\n","    # ========================================\n","    with tf.GradientTape() as disc_tape:\n","        # 1. ë…¸ì´ì¦ˆ ë° ëœë¤ ë ˆì´ë¸” ìƒì„±\n","        noise = tf.random.normal([batch_size, NOISE_DIM])\n","        fake_labels = tf.random.uniform(\n","            [batch_size, 1], minval=0, maxval=NUM_CLASSES, dtype=tf.int32\n","        )\n","\n","        # 2. ê°€ì§œ ì´ë¯¸ì§€ ìƒì„±\n","        fake_images = generator([noise, fake_labels], training=True)\n","\n","        # 3. Discriminator íŒë³„\n","        real_output = discriminator([real_images, real_labels], training=True)\n","        fake_output = discriminator([fake_images, fake_labels], training=True)\n","\n","        # 4. Loss ê³„ì‚°\n","        d_loss_real = cross_entropy(tf.ones_like(real_output), real_output)\n","        d_loss_fake = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","        d_loss = d_loss_real + d_loss_fake\n","\n","    # Discriminator gradient ê³„ì‚° ë° ì ìš©\n","    gradients_of_discriminator = disc_tape.gradient(\n","        d_loss, discriminator.trainable_variables\n","    )\n","    optimizer_d.apply_gradients(\n","        zip(gradients_of_discriminator, discriminator.trainable_variables)\n","    )\n","\n","    # ========================================\n","    # Generator í•™ìŠµ\n","    # ========================================\n","    noise = tf.random.normal([batch_size, NOISE_DIM])\n","    fake_labels = tf.random.uniform(\n","        [batch_size, 1], minval=0, maxval=NUM_CLASSES, dtype=tf.int32\n","    )\n","\n","    with tf.GradientTape() as gen_tape:\n","        fake_images = generator([noise, fake_labels], training=True)\n","        fake_output = discriminator([fake_images, fake_labels], training=True)\n","\n","        # Generator Loss: ê°€ì§œë¥¼ ì§„ì§œ(1)ë¡œ\n","        g_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n","\n","    # Generator gradient ê³„ì‚° ë° ì ìš©\n","    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n","    optimizer_g.apply_gradients(\n","        zip(gradients_of_generator, generator.trainable_variables)\n","    )\n","\n","    return d_loss, g_loss\n","\n","\n","print(\"âœ… train_step í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"]},{"cell_type":"markdown","id":"183cf8ce","metadata":{"lines_to_next_cell":2,"id":"183cf8ce"},"source":["## 2.6 ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜"]},{"cell_type":"code","execution_count":null,"id":"e4ed704f","metadata":{"id":"e4ed704f"},"outputs":[],"source":["# ê³ ì • ë…¸ì´ì¦ˆ ë° ë ˆì´ë¸” (í•™ìŠµ ê³¼ì • ë¹„êµìš©)\n","fixed_noise = tf.random.normal([NUM_CLASSES, NOISE_DIM])\n","fixed_labels = tf.reshape(tf.range(NUM_CLASSES), [-1, 1])\n","\n","\n","def generate_and_save_images(epoch, generator, noise, labels):\n","    \"\"\"ì´ë¯¸ì§€ ìƒì„± ë° ì‹œê°í™”\"\"\"\n","    predictions = generator([noise, labels], training=False)\n","\n","    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n","    for i, ax in enumerate(axes.flat):\n","        img = (predictions[i].numpy() + 1) / 2\n","        ax.imshow(img.squeeze(), cmap=\"gray\")\n","        ax.set_title(f\"{CLASS_NAMES[labels[i, 0]]}\", fontsize=10)\n","        ax.axis(\"off\")\n","\n","    plt.suptitle(f\"Epoch {epoch}\", fontsize=16)\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","# ì´ˆê¸° ì´ë¯¸ì§€\n","print(\"ğŸ¨ í•™ìŠµ ì „ Generator ì¶œë ¥\")\n","generate_and_save_images(0, generator, fixed_noise, fixed_labels)"]},{"cell_type":"markdown","id":"65acd878","metadata":{"id":"65acd878"},"source":["## 2.7 ì „ì²´ í•™ìŠµ ì‹¤í–‰"]},{"cell_type":"code","execution_count":null,"id":"84c94e89","metadata":{"id":"84c94e89"},"outputs":[],"source":["# í•™ìŠµ ì‹¤í–‰\n","print(\"=\" * 60)\n","print(\"ğŸ”¥ CGAN í•™ìŠµ ì‹œì‘ (TensorFlow)\")\n","print(\"=\" * 60)\n","\n","history_tf = {\"d_loss\": [], \"g_loss\": []}\n","\n","for epoch in range(1, EPOCHS + 1):\n","    print(f\"\\nğŸ”¥ Epoch {epoch}/{EPOCHS}\")\n","\n","    epoch_d_loss = []\n","    epoch_g_loss = []\n","\n","    for batch_idx, (real_batch, real_labels_batch) in enumerate(train_dataset):\n","        d_loss, g_loss = train_step(real_batch, real_labels_batch)\n","\n","        epoch_d_loss.append(d_loss.numpy())\n","        epoch_g_loss.append(g_loss.numpy())\n","\n","        if (batch_idx + 1) % 100 == 0:\n","            print(\n","                f\"  Batch {batch_idx + 1} - D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}\"\n","            )\n","\n","    avg_d_loss = np.mean(epoch_d_loss)\n","    avg_g_loss = np.mean(epoch_g_loss)\n","    history_tf[\"d_loss\"].append(avg_d_loss)\n","    history_tf[\"g_loss\"].append(avg_g_loss)\n","\n","    print(f\"ğŸ“Š Epoch {epoch} í‰ê·  - D Loss: {avg_d_loss:.4f}, G Loss: {avg_g_loss:.4f}\")\n","\n","    if epoch % 10 == 0:\n","        generate_and_save_images(epoch, generator, fixed_noise, fixed_labels)\n","\n","print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ!\")"]},{"cell_type":"code","execution_count":null,"id":"80577784","metadata":{"id":"80577784"},"outputs":[],"source":["# í•™ìŠµ ê³¡ì„ \n","plt.figure(figsize=(12, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history_tf[\"d_loss\"], label=\"D Loss\", color=\"blue\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Discriminator Loss\")\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history_tf[\"g_loss\"], label=\"G Loss\", color=\"red\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Generator Loss\")\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"e77dd598","metadata":{"lines_to_next_cell":2,"id":"e77dd598"},"source":["## 2.8 ì¡°ê±´ë¶€ ìƒì„± ì˜ˆì œ"]},{"cell_type":"code","execution_count":null,"id":"7f036bf7","metadata":{"id":"7f036bf7"},"outputs":[],"source":["# íŠ¹ì • í´ë˜ìŠ¤ ìƒì„±\n","def generate_specific_class_tf(class_idx, num_samples=9):\n","    \"\"\"íŠ¹ì • í´ë˜ìŠ¤ì˜ ì´ë¯¸ì§€ ìƒì„±\"\"\"\n","    noise = tf.random.normal([num_samples, NOISE_DIM])\n","    labels = tf.fill([num_samples, 1], class_idx)\n","\n","    images = generator([noise, labels], training=False)\n","\n","    rows = int(np.ceil(np.sqrt(num_samples)))\n","    cols = int(np.ceil(num_samples / rows))\n","\n","    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n","    axes = axes.flatten() if num_samples > 1 else [axes]\n","\n","    for i in range(num_samples):\n","        img = (images[i].numpy() + 1) / 2\n","        axes[i].imshow(img.squeeze(), cmap=\"gray\")\n","        axes[i].axis(\"off\")\n","\n","    for i in range(num_samples, len(axes)):\n","        axes[i].axis(\"off\")\n","\n","    plt.suptitle(f\"{CLASS_NAMES[class_idx]} Ã— {num_samples}\", fontsize=14)\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","# ìŠ¤ë‹ˆì»¤ì¦ˆ 16ê°œ ìƒì„±\n","print(\"ğŸ‘Ÿ ìŠ¤ë‹ˆì»¤ì¦ˆ 16ê°œ ìƒì„±\")\n","generate_specific_class_tf(class_idx=7, num_samples=16)"]},{"cell_type":"markdown","id":"3bae1859","metadata":{"id":"3bae1859"},"source":["---\n","# ğŸ• 3êµì‹œ: CGAN êµ¬í˜„ (PyTorch)\n","\n","---"]},{"cell_type":"markdown","id":"f4e8655f","metadata":{"id":"f4e8655f"},"source":["## 3.1 í™˜ê²½ ì„¤ì •"]},{"cell_type":"code","execution_count":null,"id":"0722f0b3","metadata":{"id":"0722f0b3"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","# GPU ì„¤ì •\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n","print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n","\n","# ëœë¤ ì‹œë“œ\n","torch.manual_seed(42)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(42)"]},{"cell_type":"markdown","id":"29109654","metadata":{"id":"29109654"},"source":["## 3.2 ë°ì´í„° ë¡œë“œ"]},{"cell_type":"code","execution_count":null,"id":"d7881eb2","metadata":{"id":"d7881eb2"},"outputs":[],"source":["# ë°ì´í„° ì „ì²˜ë¦¬\n","transform = transforms.Compose(\n","    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",")\n","\n","# Fashion MNIST ë¡œë“œ\n","train_dataset_pt = datasets.FashionMNIST(\n","    root=\"./data\", train=True, download=True, transform=transform\n",")\n","\n","train_dataloader_pt = DataLoader(\n","    train_dataset_pt, batch_size=BATCH_SIZE, shuffle=True, drop_last=True\n",")\n","\n","print(f\"ë°ì´í„°ì…‹ í¬ê¸°: {len(train_dataset_pt)}\")\n","print(f\"ë°°ì¹˜ ìˆ˜: {len(train_dataloader_pt)}\")"]},{"cell_type":"markdown","id":"844a52ae","metadata":{"lines_to_next_cell":2,"id":"844a52ae"},"source":["## 3.3 Conditional Generator êµ¬í˜„ (PyTorch)"]},{"cell_type":"code","execution_count":null,"id":"cc553ccc","metadata":{"id":"cc553ccc"},"outputs":[],"source":["class ConditionalGenerator(nn.Module):\n","    \"\"\"\n","    Conditional Generator (PyTorch)\n","\n","    êµ¬ì¡°:\n","        1. ë ˆì´ë¸” ì„ë² ë”©\n","        2. ë…¸ì´ì¦ˆ + ì„ë² ë”© ê²°í•©\n","        3. Dense + Reshape\n","        4. ConvTranspose layers\n","    \"\"\"\n","\n","    def __init__(self, noise_dim=100, num_classes=10, embedding_dim=50):\n","        super(ConditionalGenerator, self).__init__()\n","\n","        # ë ˆì´ë¸” ì„ë² ë”©\n","        self.label_embedding = nn.Embedding(\n","            num_embeddings=num_classes, embedding_dim=embedding_dim\n","        )\n","\n","        # Dense layer\n","        input_dim = noise_dim + embedding_dim\n","        self.fc = nn.Sequential(\n","            nn.Linear(input_dim, 7 * 7 * 256),\n","            nn.BatchNorm1d(7 * 7 * 256),\n","            nn.ReLU(True),\n","        )\n","\n","        # ConvTranspose layers\n","        self.main = nn.Sequential(\n","            # 7Ã—7 â†’ 14Ã—14\n","            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(True),\n","            # 14Ã—14 â†’ 28Ã—28\n","            nn.ConvTranspose2d(128, 1, 4, 2, 1, bias=False),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, z, labels):\n","        \"\"\"\n","        Args:\n","            z: (batch_size, noise_dim)\n","            labels: (batch_size,) - LongTensor\n","        \"\"\"\n","        # ë ˆì´ë¸” ì„ë² ë”©\n","        label_embed = self.label_embedding(labels)  # (batch, embedding_dim)\n","\n","        # ë…¸ì´ì¦ˆì™€ ê²°í•©\n","        gen_input = torch.cat(\n","            [z, label_embed], dim=1\n","        )  # (batch, noise_dim+embedding_dim)\n","\n","        # Dense\n","        out = self.fc(gen_input)  # (batch, 12544)\n","\n","        # Reshape\n","        out = out.view(-1, 256, 7, 7)  # (batch, 256, 7, 7)\n","\n","        # ConvTranspose\n","        img = self.main(out)  # (batch, 1, 28, 28)\n","\n","        return img\n","\n","\n","# ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Conv\") != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find(\"BatchNorm\") != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","    elif classname.find(\"Embedding\") != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","# Generator ìƒì„±\n","generator_pt = ConditionalGenerator(NOISE_DIM, NUM_CLASSES, EMBEDDING_DIM).to(device)\n","generator_pt.apply(weights_init)\n","\n","print(\"ğŸ“Š Conditional Generator (PyTorch)\")\n","print(generator_pt)"]},{"cell_type":"markdown","id":"1b3c5041","metadata":{"lines_to_next_cell":2,"id":"1b3c5041"},"source":["## 3.4 Conditional Discriminator êµ¬í˜„ (PyTorch)"]},{"cell_type":"code","execution_count":null,"id":"efddc854","metadata":{"id":"efddc854"},"outputs":[],"source":["class ConditionalDiscriminator(nn.Module):\n","    \"\"\"\n","    Conditional Discriminator (PyTorch)\n","\n","    êµ¬ì¡°:\n","        1. ë ˆì´ë¸” â†’ ì„ë² ë”© â†’ Linear â†’ 28Ã—28 ë§µ\n","        2. ì´ë¯¸ì§€ + ë ˆì´ë¸” ë§µ ê²°í•©\n","        3. Conv layers\n","    \"\"\"\n","\n","    def __init__(self, num_classes=10, embedding_dim=50):\n","        super(ConditionalDiscriminator, self).__init__()\n","\n","        self.img_size = 28\n","\n","        # ë ˆì´ë¸” ì„ë² ë”©\n","        self.label_embedding = nn.Embedding(num_classes, embedding_dim)\n","\n","        # ì„ë² ë”© â†’ 28Ã—28 ë§µ\n","        self.label_fc = nn.Linear(embedding_dim, self.img_size * self.img_size)\n","\n","        # Conv layers (ì…ë ¥ ì±„ë„: 2)\n","        self.main = nn.Sequential(\n","            # 28Ã—28 â†’ 14Ã—14\n","            nn.Conv2d(2, 64, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # 14Ã—14 â†’ 7Ã—7\n","            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        # Dense\n","        self.fc = nn.Sequential(nn.Flatten(), nn.Linear(128 * 7 * 7, 1))\n","\n","    def forward(self, img, labels):\n","        \"\"\"\n","        Args:\n","            img: (batch_size, 1, 28, 28)\n","            labels: (batch_size,) - LongTensor\n","        \"\"\"\n","        batch_size = img.size(0)\n","\n","        # ë ˆì´ë¸” ì„ë² ë”©\n","        label_embed = self.label_embedding(labels)  # (batch, embedding_dim)\n","\n","        # ì„ë² ë”© â†’ 784\n","        label_map = self.label_fc(label_embed)  # (batch, 784)\n","\n","        # Reshape to 28Ã—28Ã—1\n","        label_map = label_map.view(batch_size, 1, self.img_size, self.img_size)\n","\n","        # ì´ë¯¸ì§€ì™€ ê²°í•©\n","        disc_input = torch.cat([img, label_map], dim=1)  # (batch, 2, 28, 28)\n","\n","        # Conv layers\n","        features = self.main(disc_input)  # (batch, 128, 7, 7)\n","\n","        # Dense\n","        output = self.fc(features).view(-1)  # (batch,)\n","\n","        return output\n","\n","\n","# Discriminator ìƒì„±\n","discriminator_pt = ConditionalDiscriminator(NUM_CLASSES, EMBEDDING_DIM).to(device)\n","discriminator_pt.apply(weights_init)\n","\n","print(\"ğŸ“Š Conditional Discriminator (PyTorch)\")\n","print(discriminator_pt)"]},{"cell_type":"markdown","id":"163f9c35","metadata":{"id":"163f9c35"},"source":["## 3.5 ì†ì‹¤ í•¨ìˆ˜ ë° Optimizer"]},{"cell_type":"code","execution_count":null,"id":"371f3f73","metadata":{"id":"371f3f73"},"outputs":[],"source":["# Loss\n","criterion_pt = nn.BCEWithLogitsLoss()\n","\n","# Optimizer\n","optimizer_g_pt = optim.Adam(generator_pt.parameters(), lr=LR, betas=(BETA1, 0.999))\n","optimizer_d_pt = optim.Adam(discriminator_pt.parameters(), lr=LR, betas=(BETA1, 0.999))\n","\n","print(\"âœ… ì†ì‹¤ í•¨ìˆ˜ ë° Optimizer ì„¤ì • ì™„ë£Œ\")"]},{"cell_type":"markdown","id":"242ba802","metadata":{"lines_to_next_cell":2,"id":"242ba802"},"source":["## 3.6 í•™ìŠµ Step í•¨ìˆ˜"]},{"cell_type":"code","execution_count":null,"id":"12baa53e","metadata":{"id":"12baa53e"},"outputs":[],"source":["def train_step_pt(real_images, real_labels):\n","    \"\"\"CGAN í•œ ìŠ¤í… í•™ìŠµ (PyTorch)\"\"\"\n","    batch_size = real_images.size(0)\n","    real_images = real_images.to(device)\n","    real_labels = real_labels.to(device)\n","\n","    # íƒ€ê²Ÿ\n","    real_target = torch.ones(batch_size, device=device)\n","    fake_target = torch.zeros(batch_size, device=device)\n","\n","    # ========================================\n","    # Discriminator í•™ìŠµ\n","    # ========================================\n","    discriminator_pt.zero_grad()\n","\n","    # ì§„ì§œ ì´ë¯¸ì§€\n","    real_output = discriminator_pt(real_images, real_labels)\n","    d_loss_real = criterion_pt(real_output, real_target)\n","\n","    # ê°€ì§œ ì´ë¯¸ì§€\n","    noise = torch.randn(batch_size, NOISE_DIM, device=device)\n","    fake_labels = torch.randint(0, NUM_CLASSES, (batch_size,), device=device)\n","    fake_images = generator_pt(noise, fake_labels)\n","    fake_output = discriminator_pt(fake_images.detach(), fake_labels)\n","    d_loss_fake = criterion_pt(fake_output, fake_target)\n","\n","    # D Loss\n","    d_loss = d_loss_real + d_loss_fake\n","    d_loss.backward()\n","    optimizer_d_pt.step()\n","\n","    # ========================================\n","    # Generator í•™ìŠµ\n","    # ========================================\n","    generator_pt.zero_grad()\n","\n","    noise = torch.randn(batch_size, NOISE_DIM, device=device)\n","    fake_labels = torch.randint(0, NUM_CLASSES, (batch_size,), device=device)\n","    fake_images = generator_pt(noise, fake_labels)\n","    fake_output = discriminator_pt(fake_images, fake_labels)\n","\n","    # G Loss\n","    g_loss = criterion_pt(fake_output, real_target)\n","    g_loss.backward()\n","    optimizer_g_pt.step()\n","\n","    return d_loss.item(), g_loss.item()\n","\n","\n","print(\"âœ… train_step í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"]},{"cell_type":"markdown","id":"0fd549c6","metadata":{"id":"0fd549c6"},"source":["## 3.7 ì „ì²´ í•™ìŠµ ì‹¤í–‰"]},{"cell_type":"code","execution_count":null,"id":"382bfee8","metadata":{"id":"382bfee8"},"outputs":[],"source":["# ê³ ì • ë…¸ì´ì¦ˆ\n","fixed_noise_pt = torch.randn(NUM_CLASSES, NOISE_DIM, device=device)\n","fixed_labels_pt = torch.arange(NUM_CLASSES, device=device)\n","\n","\n","def generate_and_save_images_pt(epoch, generator, noise, labels):\n","    \"\"\"ì´ë¯¸ì§€ ìƒì„± (PyTorch)\"\"\"\n","    generator.eval()\n","\n","    with torch.no_grad():\n","        fake_images = generator(noise, labels).cpu()\n","\n","    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n","    for i, ax in enumerate(axes.flat):\n","        img = fake_images[i].squeeze().numpy()\n","        img = (img + 1) / 2\n","        ax.imshow(img, cmap=\"gray\")\n","        ax.set_title(f\"{CLASS_NAMES[labels[i]]}\", fontsize=10)\n","        ax.axis(\"off\")\n","\n","    plt.suptitle(f\"Epoch {epoch}\", fontsize=16)\n","    plt.tight_layout()\n","    plt.show()\n","\n","    generator.train()\n","\n","\n","# ì´ˆê¸° ì´ë¯¸ì§€\n","print(\"ğŸ¨ í•™ìŠµ ì „ Generator ì¶œë ¥ (PyTorch)\")\n","generate_and_save_images_pt(0, generator_pt, fixed_noise_pt, fixed_labels_pt)"]},{"cell_type":"code","execution_count":null,"id":"f9399686","metadata":{"id":"f9399686"},"outputs":[],"source":["# í•™ìŠµ ì‹¤í–‰\n","print(\"=\" * 60)\n","print(\"ğŸ”¥ CGAN í•™ìŠµ ì‹œì‘ (PyTorch)\")\n","print(\"=\" * 60)\n","\n","history_pt = {\"d_loss\": [], \"g_loss\": []}\n","\n","for epoch in range(1, EPOCHS + 1):\n","    print(f\"\\nğŸ”¥ Epoch {epoch}/{EPOCHS}\")\n","\n","    epoch_d_loss = []\n","    epoch_g_loss = []\n","\n","    for batch_idx, (real_batch, real_labels_batch) in enumerate(train_dataloader_pt):\n","        d_loss, g_loss = train_step_pt(real_batch, real_labels_batch)\n","\n","        epoch_d_loss.append(d_loss)\n","        epoch_g_loss.append(g_loss)\n","\n","        if (batch_idx + 1) % 100 == 0:\n","            print(\n","                f\"  Batch {batch_idx + 1} - D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}\"\n","            )\n","\n","    avg_d_loss = np.mean(epoch_d_loss)\n","    avg_g_loss = np.mean(epoch_g_loss)\n","    history_pt[\"d_loss\"].append(avg_d_loss)\n","    history_pt[\"g_loss\"].append(avg_g_loss)\n","\n","    print(f\"ğŸ“Š Epoch {epoch} í‰ê·  - D Loss: {avg_d_loss:.4f}, G Loss: {avg_g_loss:.4f}\")\n","\n","    if epoch % 10 == 0:\n","        generate_and_save_images_pt(\n","            epoch, generator_pt, fixed_noise_pt, fixed_labels_pt\n","        )\n","\n","print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ!\")"]},{"cell_type":"code","execution_count":null,"id":"df899ecb","metadata":{"id":"df899ecb"},"outputs":[],"source":["# í•™ìŠµ ê³¡ì„ \n","plt.figure(figsize=(12, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history_pt[\"d_loss\"], label=\"D Loss\", color=\"blue\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Discriminator Loss (PyTorch)\")\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history_pt[\"g_loss\"], label=\"G Loss\", color=\"red\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Generator Loss (PyTorch)\")\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"0a14e339","metadata":{"id":"0a14e339"},"source":["---\n","# ğŸ“ ì •ë¦¬ ë° ë‹¤ìŒ ì‹œê°„ ì˜ˆê³ \n","\n","---"]},{"cell_type":"markdown","id":"c165b4bf","metadata":{"id":"c165b4bf"},"source":["## ğŸ¯ Day 3 í•µì‹¬ ìš”ì•½\n","\n","### 1. CGANì˜ í•µì‹¬\n","\n","- **ì¡°ê±´ ì •ë³´ ì¶”ê°€:** GANì— ì¡°ê±´ yë¥¼ ì¶”ê°€í•˜ì—¬ ìƒì„± ì œì–´\n","- **Generator:** G(z, y) â†’ ì¡°ê±´ì— ë§ëŠ” ì´ë¯¸ì§€\n","- **Discriminator:** D(x, y) â†’ ì´ë¯¸ì§€ì™€ ì¡°ê±´ì˜ í˜ì–´ë§ íŒë³„\n","\n","### 2. ì¡°ê±´ ê²°í•© ë°©ì‹\n","\n","| ë°©ì‹ | íŠ¹ì§• | ì í•©í•œ ê²½ìš° |\n","|------|------|-----------|\n","| **One-Hot** | ê°„ë‹¨, íŒŒë¼ë¯¸í„° ì ìŒ | í”„ë¡œí† íƒ€ì…, í´ë˜ìŠ¤ ì ìŒ |\n","| **Embedding** | ìœ ì‚¬ë„ í•™ìŠµ ê°€ëŠ¥ | ì¼ë°˜ì ì¸ CGAN |\n","| **Projection** | ìµœê³  ì„±ëŠ¥ | ëŒ€ê·œëª¨, ê³ í’ˆì§ˆ í•„ìš” |\n","\n","\n","### 3. CGANì˜ ì¥ì \n","\n","- âœ… ìƒì„± ì œì–´ ê°€ëŠ¥ (ì›í•˜ëŠ” í´ë˜ìŠ¤ ì§€ì •)\n","- âœ… í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ (ì¡°ê±´ ì •ë³´ê°€ ê°€ì´ë“œ ì—­í• )\n","- âœ… ë‹¤ì–‘í•œ ì‘ìš© (Image-to-Image Translation ë“±)"]}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"L4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}